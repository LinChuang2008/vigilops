# 用 AI 给运维告警降噪：从理想到现实

> 作者：VigilOps 团队 | 2026-02

---

## "AI 降噪"听起来很美

打开任何一个 AIOps 产品的官网，你都会看到类似的承诺："AI 驱动的告警降噪，减少 90% 噪音"。这些数字看起来令人激动，但在真实运维环境中，事情远没那么简单。

这篇文章不讲营销话术。我们会分享在 VigilOps 中使用 AI（DeepSeek LLM）做告警降噪的实际做法、遇到的坑，以及什么有效、什么没效。

## 先搞清楚"噪音"是什么

运维告警中的噪音大致分几类：

**重复告警。** 同一个问题在一分钟内触发了 10 条告警（比如 10 个 Pod 同时报内存高）。AlertManager 的分组功能可以处理大部分情况，但前提是告警的标签要设计得好。

**自恢复告警。** CPU 突然飙到 95%，一分钟后降回正常，触发了告警但恢复得太快来不及处理。这类告警对值班人员来说基本是噪音，但完全屏蔽又怕漏掉持续性问题。

**关联告警。** 一个上游服务挂了，导致下游 5 个服务同时报错。本质上只有一个根因，但你收到了 6 条告警。

**阈值不合理告警。** 磁盘使用率告警设在 80%，但你的服务器一直稳定在 78-82% 之间。这个告警每周都会触发几次，每次都不需要处理。

**真正的噪音只有一种定义：触发了但不需要任何人做任何事的告警。** 其他的，哪怕短暂的，也可能包含有价值的信息。

## 传统降噪方法的上限

在引入 AI 之前，运维团队通常用这些方法降噪：

### 分组和抑制

AlertManager 的 `group_by` 和 `inhibit_rules` 是基础。把同一服务的同类告警分组，设置关键告警抑制次要告警。效果不错，但需要手动维护规则，且无法处理跨服务的关联。

### 静默和维护窗口

计划维护期间静默告警是标准做法。但"临时静默"容易被忘记取消，变成永久的盲区。

### 告警聚合和去重

商业工具（如 PagerDuty Event Intelligence）用统计方法对告警做聚合去重。效果因场景而异，通常能减少 30-50% 的通知量。

### 阈值调优

定期回顾告警规则，调高不合理的阈值，删除长期不触发或频繁触发但从不处理的规则。这是成本最低但最容易被忽略的方法。

**这些方法的共同上限：它们是基于规则的，无法理解上下文。** 一条"CPU 95%"的告警，在日常场景和大促期间意味着完全不同的事情，但基于规则的系统看到的只是一个数字。

## AI 降噪在 VigilOps 中怎么工作

我们在 VigilOps 中集成了 DeepSeek（大语言模型）来做告警分析。这不是一个独立的"AIOps 模块"，而是嵌入在告警处理流程中的一个分析步骤。

### 具体流程

```
告警触发
    ↓
收集上下文：
  - 告警指标的最近 30 分钟趋势
  - 同一主机的其他活跃告警
  - 最近的相关日志（关键词匹配）
  - 服务拓扑中的上下游关系
    ↓
构建 Prompt，发送给 DeepSeek：
  - "以下是一条运维告警及其上下文，请分析根因和建议"
    ↓
AI 返回：
  - 可能的根因
  - 严重程度评估
  - 建议操作（包括是否可以自动修复）
    ↓
根据分析结果：
  - 匹配 Runbook → 自动修复
  - 不匹配 → 附加分析结果后通知
```

### 什么有效

**根因关联。** 当 5 个下游服务同时报错时，AI 能结合拓扑信息判断"这些可能都源自上游服务 X 的故障"。这在人工分析时很直觉，但基于规则的系统做不到。

**日志解读。** AI 可以阅读错误日志，解释"这个 OOM Killed 是因为 Java 堆内存配置过小"。对于经验不足的值班人员，这相当于一个高级工程师在旁边给解释。

**和自动修复联动。** AI 分析"磁盘满了，原因是 /var/log 下的应用日志没有轮转"→ 匹配 `log_rotation` Runbook → 自动执行。整个链路是连贯的。

### 什么没效（诚实说）

**延迟。** LLM 分析需要时间。DeepSeek API 调用通常需要 3-8 秒，加上上下文收集和 Prompt 构建，一次分析总延迟在 5-15 秒。对于需要立即响应的 P0 告警，这个延迟是不可接受的。

我们的做法：对 P0 级别的告警，跳过 AI 分析，直接发送告警通知。AI 分析异步执行，结果后续补充到告警详情中。

**幻觉。** LLM 有时会编造看起来合理但实际上错误的根因分析。比如它可能说"这是因为最近的部署导致内存泄漏"，但实际上根本没有最近的部署。

我们的做法：AI 分析结果标记为"参考"而非"结论"，同时要求 AI 标注置信度。低置信度的分析不会触发自动修复。

**成本。** 每条告警都调用 LLM API 是有成本的。按 DeepSeek 的价格，单次分析几分钱，但告警量大时日积月累也不少。

我们的做法：只对非重复、非已静默的告警触发 AI 分析。分组后的告警只分析一次。

## 你可以自己验证

如果你想试试 AI 告警分析的效果，最简单的方式：

```bash
# 部署 VigilOps
git clone https://github.com/LinChuang2008/vigilops.git
cd vigilops
cp .env.example .env
# 在 .env 中填入 DeepSeek API Key
docker compose up -d
```

或者直接看在线 Demo：[http://139.196.210.68:3001](http://139.196.210.68:3001)（`demo@vigilops.io` / `demo123`）

在告警详情页，你可以看到 AI 分析结果字段，包括根因推断、严重程度评估和建议操作。

## 几个实用建议

不管你是否用 VigilOps，以下是我们在实践中总结的告警降噪建议：

**1. 先做最简单的事：清理告警规则。** 导出你所有的告警规则，按过去 30 天的触发次数排序。触发最多的那 10 条规则，逐一审视：是阈值不合理？还是这个指标本身就不适合做告警？

**2. 分层告警，不要一视同仁。** 不是所有告警都需要发到钉钉群。分三层：
- P0：电话/短信叫醒（服务不可用）
- P1：即时通讯通知（需要关注但不紧急）
- P2/P3：写到面板上就行（信息性质）

**3. 衡量告警质量，而不只是告警数量。** 跟踪两个指标：
- **噪音比**：触发后未被人工操作的告警占比
- **漏报率**：没有告警但出了问题的次数

理想状态是噪音比 < 30%，漏报率趋近于 0。

**4. 对 AI 降噪保持合理预期。** AI 不是银弹。它能帮你做上下文关联和根因推断，但阈值调优、规则治理这些基本功还是要人来做。把 AI 当作一个经验丰富的同事，而不是一个魔法按钮。

## 总结

告警降噪是一个系统工程，不是一个功能开关。最有效的方法是分层的：

1. **基础层**：合理的告警规则 + 分组 + 抑制（AlertManager 就能做）
2. **智能层**：AI 上下文分析 + 根因关联（VigilOps 在做的）
3. **自动化层**：对已知问题自动修复（Runbook 引擎）
4. **治理层**：定期回顾 + 指标驱动的优化（需要团队文化）

VigilOps 在第 2 层和第 3 层做了尝试。效果还在持续迭代中，我们不会声称"减少 90% 噪音"——这取决于你的具体环境和告警规则质量。

但方向是确定的：监控系统应该越来越智能，而不是越来越吵。

---

*VigilOps 是一个 Apache 2.0 开源项目。GitHub：[LinChuang2008/vigilops](https://github.com/LinChuang2008/vigilops)*
